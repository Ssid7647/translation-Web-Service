#URL => https://www.cdac.in/index.aspx?id=print_page&print=ev_hpc_upc_programs
hyPACK-2013
About
Tech Program
Multicore
ARM
Coprocessor
GPUs
Cluster
Applications
Registration
Multicore Technologies
Mode-1 Multi-cores
Memory Allocators
OpenMP
Intel TBB
Pthreads
Java - Threads
Charm++ Prog.
Message Passing (MPI)
MPI-OpenMP
MPI-Intel TBB
MPI-Pthread
Compiler Opt. Features
Threads-Perf.
Math. lib.
Threads-Prof.
& tools
Threads-I/O Perf.
PGAS:UPC/CAF/GA
Home
PGAS - Unified Parallel C (UPC)
Contents
Overview
UPC programs to illustrate basic upc API library calls
Unified Parallel C (UPC) is an extension of C for programming multiprocessors with a shared address space.
UPC is designed to use message passing techniques to simulate a shared memory multiprocess environment.
UPC is also designed to support the Distributed Shared Memory Model, which is in between the Distributed Memory Model and the Shared Memory Model.
It has numerous features designed to make parallelisation as simple as possible, whilst also attempting to preserve the efficiency and overall structure of C. The hope is to achieve the balance between the ease of use (of the shared memory model) and the ability to exploit data locality (of the message passing model).
It provides a Partitioned Global Address Space for the transfer of data between processes, as well as numerous synchronization and collective functions that enable the control of program flow between parallel threads.
UPC is supported on both shared- and distributed-memory systems and presents the programmer with a logically partitioned global address space that is physically distributed across available memory domains.
Under UPC, every shared data element has affinity to a distinct processor, and UPC exposes this data locality information to the programmer so that it can be leveraged to enhance performance.
Shared data can be accessed through built-in language-level support as well as through explicit one-sided communication operations.
Regardless of location, all data in the global address space can be accessed without explicit help from the data's owner.
UPC provides a common syntax and semantics for explicit parallel programming in C, and it directly maps language features to the underlying architecture.
UPC is an example of the partitioned shared memory programming model in which shared memory is partitioned among all UPC threads (processes).
This partition is formally represented in the programming language.
Each thread can access any location in shared memory using the same syntax but the locations in each thread's own partition of shared memory are accessed more quickly.
The idea behind UPC is that users should be able to view the underlying machine model as a collection of threads operating in a common global address space.
Specifically, each thread can access data resident in:
the local part of the address space
the shared part of the address space with affinity to that thread the shared part of the address space with affinity to other threads
There is no explicit message passing, as UPC features are at a significantly higher-level than MPI.
UPC has been gaining interests from academia, industry and government labs.
A UPC consortium , Berkeley UPC - Unified Parallel C , & GCC Unified Parallel C (GCC UPC) and other has been formed to foster and coordinate UPC development and research activities.
Several organizations including academia, vendors, government, and supercomputing centers all over the world are actively involved in UPC research and development.
Most of the work is focused on UPC Complier implementations such as GCC-based compiler.
header
