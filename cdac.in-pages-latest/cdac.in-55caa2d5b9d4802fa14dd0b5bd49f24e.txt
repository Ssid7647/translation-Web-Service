#URL => https://www.cdac.in/index.aspx?id=ev_hpc_iothreads_pthread_mpiprogs
hyPACK-2013
Reach Us
Skip to navigation
Skip to main content
C-DAC Centres
Bengaluru
Chennai
Delhi
Hyderabad
Kolkata
Mohali
Mumbai
Noida
Patna
Pune
Silchar
Thiruvananthapuram
Sitemap
Blog
Choose Language
Assamese
Bangla
Bodo
Dogri
Gujarati
Kannada
Konkani
Kashmiri
Kashmiri-Keshur
Maithili
Malayalam
Manipuri
Manipuri (N)
Marathi
Nepali
Oriya
Punjabi
Santali
Santali (N)
Sanskrit
Sindhi
Sindhi (N)
Tamil
Telugu
Urdu
Translation powered by GoTranslate
Regional Language Policy
A-
A+
Toggle navigation
Home
About C-DAC (current)
Products & Services
Research & Development
Press Kit
Downloads
Careers
Tenders
Contact Us
Search
Events
Tech Program
Multicore
ARM
Coprocessor
GPUs
Cluster
Applications
Multicore Technologies
Mode-1 Multi-cores
Memory Allocators
OpenMP
Intel TBB
Pthreads
Java - Threads
Charm++ Prog.
Message Passing (MPI)
MPI-OpenMP
MPI-Intel TBB
MPI-Pthread
Compiler Opt. Features
Threads-Perf.
Math. lib.
Threads-Prof.
& tools
Threads-I/O Perf.
PGAS:UPC/CAF/GA
Thread-I/O Perf.
Contents
Overview
Programs
Simple programs using MPI 2 I/O library calls and threaded I/O programs are executed on Message Passing Cluster or Multi-Core Processor Systems that support MPI library.
Example 1.1
Write a simple MPI I/O program performing sequential I/O to multiple files
Example 1.2
Write a Pthread I/O program performing each thread writing to separate file
(  Assignment  )
Example 1.3
Write an MPI program performing MPI I/O to separate files (Using MPI 2.0)
Example 1.4
Write an MPI program performing MPI I/O to single file (Using MPI 2.0)
Example 1.5
Write an Pthread I/O program reading the file with different number of threads.
(  Assignment  )
Example 1.6
Write a MPI I/O program to read the file with different number of processes.
(Using MPI 2.0)
Description of Threaded & MPI 2.0 I/O Programs on Multi-Core Processors
Example 1.1 :   Write a simple MPI I/O program performing sequential I/O to multiple files
( Download source code : ) non-mpi-par-io-multiple-files.c
Objective
Write a simple MPI I/O program performing sequential I/O to multiple files
This is a very simple program to get the feel of how threads perform sequential I/O.
For simplicity, we use MPI Basic library calls.
we assume the each process has set of  n  integers of the array with total length depends upon on how many processes there are.
Each process has block of integers in each process's memory and each process writes to an appropriate location of global array.
The program begins with each process initializing its portion of the array.
All process except first process writes data.
The first process writes its data and reads all the data form other process and first process write the data to file.
Input
None
Output
Output file data
Example 1.2 :   Write a Pthread I/O program performing each thread writing to separate file
Objective
Write a Pthread I/O program performing each thread writing to separate file
In this example, thread parallelism is introduced.
Each thread writes to separate file thus, enabling parallel data transfer..
For simplicity, we assume the each thread has set of  n  integers of the array with total length depends upon on how many threads there are.
Each thread has block of integers in each thread's memory and each thread writes to separate file.
Each thread opens file, writes to it, and closes it.
Written files are separated by appending each thread  id  to the name of its output file.
Here, the I/O operations can take place in parallel but set of files are in use instead of a single file.
The flow of writing data files have advantages and dis-advantages which merely depends upon nature of application.
The application requirements such as (a). need of one file in which all the files may have to be joined together in specific order, (b).
All the threads may concurrently read these files, and (c).
Keep track of number of files as a group for moving them, or copying them or sending them across a network.
None
Set of output files
Example 1.3 :   Write an MPI program performing MPI I/O (Writing) to separate files (Using MPI 2.0)
( Download source code : ) mpi-io-multiple-files.c
Objective
Write an MPI program performing MPI I/O to separate files (Using MPI 2.0)
This example show how familiar I/O operations look in MPI 2.0. MPI 2.0 I/O Library calls is used in this example.
Each process writes to separate files in parallel using MPI 2.0 library calls.
For simplicity, we assume the each process has set of  n  integers of the array with total length depends upon on how many process  p  there are.
Each process has block of integers in each process memory and each process writes to separate file.
Each process opens file, writes to it, and closes it.
Written files are separated by appending each process's  rank  to the name of its output file.
The declaration of  FILE, open, close, write is done using MPI functions.
The MPI program is easy to understand and from performance point of view, the quantification of MPI I/O overheads is required.
MPI_COMM_SELF  library call is used and it indicates that only one process is involved while opening the file.
The input file holding the square matrix
Set of Output files
Example 1.4 :   Write an MPI program performing MPI I/O to single file (Using MPI 2.0).
( Download source code : ) mpi-io-write-single-file.c
Objective
Write an MPI program performing MPI I/O (Writing) to single file (Using MPI 2.0).
MPI process share a single file instead of the writing to separate files, thus avoiding the having multiple files as discussed on example 1.3.
This shows performance advantages of parallelism adopted using MPI.
The new library calls of MPI are used to sharing a a file among processes.
Here,  MPI_COMM_WORLD  library call is used instead of  MPI_COMM_SELF  library call.
This indicates that all the processes are opening a single file together and it is a collective operations on the communicator, on all participating process.
The input file holding the square matrix (Number of Rows, Columns of the matrix)
Single Output file
Example 1.5 :   Write an Pthread I/O program reading the file with different number of threads
Objective
This example demonstrates how to read a file involving all the threads.
All the participating threads globally share the input data file and all the threads concurrently read a portion of the data file.
We assume the each thread read set of  n/p  integers of the array in which the input data file size is of  n  is globally accessible by all p threads.
We assume that  n  is divisible by  p  Each thread writes the output data which consists of block of integers Here, the I/O operations can take place in parallel but set of files written by each thread.
None
Output file for each thread
Example 1.6 :   Write a MPI I/O program to read a file with different no. of processes (Using MPI 2.0)
( Download source code : ) mpi-io-par-read-multiple-files.c
Objective
Write a MPI I/O program to read the file with different no. of processes (Using MPI 2.0).
This example program demonstrates reading of a file involving all the MPI process.
The program is independent of the number of processes that run it.
The new MPI library call  MPI_File_get_size  library call is used to know about the size of the file which is stored in bytes.
MPI defines a type  MPI_Offset , that is large enough to contain a file size.
Each process writes the contents of reading file.
None
Each Process Output file.
High Performance Computing,
Grid & Cloud Computing
Multilingual Computing & Heritage Computing
Professional Electronics,
VLSI & Embedded Systems
Software Technologies including FOSS
Cyber Security & Cyber Forensics
Health Informatics
Education & Training
Related Links
Office Contact Information
Career Opportunities
Website Policies
Copyright Policy
Terms & Conditions
Help
Â© 2021
C-DAC.
All rights reserved
Last Updated: Tuesday, January 30, 2018
Website owned & maintained by: Centre for Development of Advanced Computing (C-DAC)
Top
C-DAC LOGO
Manipuri(N)
Santali(N)
Sindhi(N)
dbg
lbg
MEITY
Digital India
Azadi Ka Amrit Mahotsav
India.gov
BHIM
Swachh Bharat
Koo
Facebook
linkedin
twitter
